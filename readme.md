<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [Transformer](#transformer)
- [Vision Transformer](#vision-transformer)

<!-- /code_chunk_output -->

# Transformer

- Code: [Jupyter Notebook](https://github.com/git-ai-zyy/Pytorch-DeepLearning/blob/main/Transformer.ipynb)
- Blog: [Transformer](https://yuyangs-project.super.site/another-page)
- Recommend: ⭐️⭐️⭐️⭐️⭐️ (Highly Recommend)
- Description:
  - Transformer is a model architecture that is based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.
  - It is one of the most popular and important model architectures in the field of natural language processing (NLP) and the foundation of the state-of-the-art models.
- Reference:
  - [Attention is All You Need](https://arxiv.org/abs/1706.03762)
  - [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)
  - [The Annotated Transformer](https://nlp.seas.harvard.edu/annotated-transformer/)

---

# Vision Transformer

- Code: [Jupyter Notebook](https://github.com/git-ai-zyy/Pytorch-DeepLearning/blob/main/VisionTransformer.ipynb)
- Blog: [Vision Transformer](https://yuyangs-project.super.site/another-pagess)
- Recommend: ⭐️⭐️⭐️⭐️⭐️ (Highly Recommend)
- Description:
  - Vision Transformer (ViT) is a transformer-based model for image recognition.
  - It applies the transformer architecture to image classification by treating images as sequences of patches.
- Reference:
  - [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)
